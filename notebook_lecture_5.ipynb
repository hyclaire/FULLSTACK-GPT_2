{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hello\\nAI: Hi there!\\nHuman: Hello2\\nAI: Hi there!2\\nHuman: Hello3\\nAI: Hi there!3\\nHuman: Hello4\\nAI: Hi there!4'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat gpt example\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"Hi there!\"})\n",
    "memory.save_context({\"input\": \"Hello2\"}, {\"output\": \"Hi there!2\"})\n",
    "memory.save_context({\"input\": \"Hello3\"}, {\"output\": \"Hi there!3\"})\n",
    "memory.save_context({\"input\": \"Hello4\"}, {\"output\": \"Hi there!4\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hello2\\nAI: Hi there!2\\nHuman: Hello3\\nAI: Hi there!3\\nHuman: Hello4\\nAI: Hi there!4'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "memory2 = ConversationBufferWindowMemory(k=3)  # Stores last 3 interactions\n",
    "memory2.save_context({\"input\": \"Hello\"}, {\"output\": \"Hi there!\"})\n",
    "memory2.save_context({\"input\": \"Hello2\"}, {\"output\": \"Hi there!2\"})\n",
    "memory2.save_context({\"input\": \"Hello3\"}, {\"output\": \"Hi there!3\"})\n",
    "memory2.save_context({\"input\": \"Hello4\"}, {\"output\": \"Hi there!4\"})\n",
    "\n",
    "memory2.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4'),\n",
       "  HumanMessage(content='5'),\n",
       "  AIMessage(content='5')]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.save_context({\"input\" : \"Hi!\"}, {\"output\" : \"How are you?\"})\n",
    "\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "memory_window = ConversationBufferWindowMemory(\n",
    "    return_messages=True,\n",
    "    k=4\n",
    ")\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory_window.save_context({\"input\": input}, {\"output\" : output})\n",
    "\n",
    "add_message(1, 1)\n",
    "add_message(2, 2)\n",
    "add_message(3, 3)\n",
    "add_message(4, 4)\n",
    "\n",
    "memory_window.load_memory_variables({})\n",
    "\n",
    "add_message(5, 5) #hit the limit\n",
    "memory_window.load_memory_variables({}) # 1 is gone\n",
    "\n",
    "#-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"The human introduces himself as John from South Korea. The AI responds with enthusiasm about John's location, expressing a desire to visit because it's cold there.\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "memory_conversation = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "def add_message_converstaion(input, output):\n",
    "    memory_conversation.save_context({\"input\": input}, {\"output\" : output})\n",
    "\n",
    "def get_history():\n",
    "    return memory_conversation.load_memory_variables({})\n",
    "\n",
    "add_message_converstaion(\"Hi my name is John, I live in South Korea\", \"Wow that is so cool\")\n",
    "add_message_converstaion(\"South Korea is so cold\", \"I wish I want to visit.\")\n",
    "\n",
    "get_history() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=150,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\": \"Can you tell me about the history of South Korea?\"},\n",
    "    {\"output\": \"South Korea was officially established in 1948 after the Korean Peninsula was divided following World War II. The country has undergone rapid economic and technological growth since the Korean War (1950-1953).\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\": \"What are some major traditional festivals in Korea?\"},\n",
    "    {\"output\": \"Some major festivals include Seollal (Lunar New Year), Chuseok (Korean Thanksgiving), and the Lotus Lantern Festival. These celebrations involve family gatherings, traditional food, and rituals.\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\": \"What is a famous Korean dish?\"},\n",
    "    {\"output\": \"One of the most famous Korean dishes is Kimchi, a fermented vegetable dish typically made with napa cabbage and radish. It's a staple in Korean cuisine.\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\": \"What are some must-try Korean street foods?\"},\n",
    "    {\"output\": \"Popular Korean street foods include Tteokbokki (spicy rice cakes), Hotteok (sweet pancakes), and Odeng (fish cakes). These can be found at markets like Myeongdong and Gwangjang Market.\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human asks the AI about the history of South Korea. The AI explains that South Korea was officially established in 1948 after the Korean Peninsula was divided following World War II, and has experienced rapid economic and technological growth since the Korean War (1950-1953). The AI also mentions some major traditional festivals in Korea, such as Seollal, Chuseok, and the Lotus Lantern Festival, which involve family gatherings, traditional food, and rituals.'),\n",
       "  HumanMessage(content='What is a famous Korean dish?'),\n",
       "  AIMessage(content=\"One of the most famous Korean dishes is Kimchi, a fermented vegetable dish typically made with napa cabbage and radish. It's a staple in Korean cuisine.\"),\n",
       "  HumanMessage(content='What are some must-try Korean street foods?'),\n",
       "  AIMessage(content='Popular Korean street foods include Tteokbokki (spicy rice cakes), Hotteok (sweet pancakes), and Odeng (fish cakes). These can be found at markets like Myeongdong and Gwangjang Market.')]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"South Korea is so pretty\", \"I wish I could go!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm Nicolas, I live in South Korea\"),\n",
       "  AIMessage(content='Wow that is so cool!'),\n",
       "  HumanMessage(content='South Korea is so pretty'),\n",
       "  AIMessage(content='I wish I could go!!!')]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "add_message(\"How far is Korea from Argentina?\", \"I don't know! Super far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm Nicolas, I live in South Korea\"),\n",
       "  AIMessage(content='Wow that is so cool!'),\n",
       "  HumanMessage(content='South Korea is so pretty'),\n",
       "  AIMessage(content='I wish I could go!!!'),\n",
       "  HumanMessage(content='How far is Korea from Argentina?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\")]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"How far is Brazil from Argentina?\", \"I don't know! Super far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='Nicolas introduces himself as living in South Korea. The AI responds by expressing admiration for his location and wishing it could go there. The human then asks how far Korea is from Argentina.'),\n",
       "  AIMessage(content=\"I don't know! Super far!\"),\n",
       "  HumanMessage(content='How far is Brazil from Argentina?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\"),\n",
       "  HumanMessage(content='How far is Brazil from Argentina?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\"),\n",
       "  HumanMessage(content='How far is Brazil from Argentina?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\"),\n",
       "  HumanMessage(content='How far is Brazil from Argentina?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\"),\n",
       "  HumanMessage(content='How far is Brazil from Argentina?'),\n",
       "  AIMessage(content=\"I don't know! Super far!\")]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Nicolas: Nicolas lives in South Korea.')]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationKGMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")\n",
    "\n",
    "memory.load_memory_variables({\"input\": \"who is Nicolas\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Nicolas: Nicolas lives in South Korea. Nicolas likes kimchi.')]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\"Nicolas likes kimchi\", \"Wow that is so cool!\")\n",
    "\n",
    "memory.load_memory_variables({\"inputs\": \"what does Nicolas like\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On sam: sam is a friend. sam favorite color is red.')]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory5 = ConversationKGMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "memory5.save_context({\"input\": \"say hi to sam\"}, {\"output\": \"who is sam\"})\n",
    "memory5.save_context({\"input\": \"sam is a friend\"}, {\"output\": \"okay\"})\n",
    "memory5.save_context({\"input\": \"sam's favorite color is red.\"}, {\"output\": \"okay\"})\n",
    "\n",
    "memory5.load_memory_variables({\"input\": \"who is sam?\"})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
